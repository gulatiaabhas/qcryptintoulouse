<rss xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:content="http://purl.org/rss/1.0/modules/content/" xmlns:atom="http://www.w3.org/2005/Atom" version="2.0"><channel><title><![CDATA[obsidian-notes]]></title><description><![CDATA[Obsidian digital garden]]></description><link>http://github.com/dylang/node-rss</link><image><url>site-lib/media/favicon.png</url><title>obsidian-notes</title><link/></image><generator>Webpage HTML Export plugin for Obsidian</generator><lastBuildDate>Wed, 26 Nov 2025 12:34:10 GMT</lastBuildDate><atom:link href="site-lib/rss.xml" rel="self" type="application/rss+xml"/><pubDate>Wed, 26 Nov 2025 12:34:07 GMT</pubDate><ttl>60</ttl><dc:creator/><item><title><![CDATA[QCrypt in Toulouse: Key Distribution]]></title><description><![CDATA[These are notes for the third session of the Quantum Cryptography Workgroup in Toulouse. More info can be found <a data-tooltip-position="top" aria-label="https://gulatiaabhas.github.io/qcryptintoulouse/" rel="noopener nofollow" class="external-link is-unresolved" href="https://gulatiaabhas.github.io/qcryptintoulouse/" target="_self">here</a>.In the previous two sessions we have introduced the fundamental ideas underlying (quantum) cryptography and developed helpful mathematical tools. We now want to distribute actual keys. First classically, then quantumly. Definition. A key distribution protocol is a protocol that lets Alice and Bob agree on an -bit key . It is -correct if the protocol succeeds with probability at least , that is, if Alice and Bob have derived keys according to the protocol then .
-secure if an eavesdropper Eve is almost ignorant about the key, that is . Such a protocol may work only under specific assumptions on the communication channels that Bob and Alice have access to. Generally, we will distinguish between the following types of communication channels.
Classical channel
Classical authenticated channel
Classical secret channel
Classical secret and authenticated channel
Quantum channel
As a warmup, let us consider a purely classical protocol in a toy model. We assume that Alice and Bob have access to a classical authenticated channel (CAC) and want to establish a key over a classical channel to which Eve has limited access in the following sense. If Alice sends a bit over the channel,
Bob correctly receives Eve receives with probability and with probability .
The induced channel Alice Eve is also called the binary symmetric channel in the information theory literature.Recall the definition of an -strong seeded extractor.
Definition. A -strong seeded extractor is a function such that for any qc state with , Now consider the following protocol.
Protocol 1 -- Key distribution over a special channel. Alice chooses uniformly at random and sends the bits over the channel.
Alice picks random seed and applies an -strong seeded extractor to , computing .
Alice sends over the CAC.
Bob computes . Clearly the protocol is -correct, as there are no errors in the communication between Bob and Alice, and they compute the same function to obtain the key .It is also not hard to see that the protocol is -secure. Recall that we introduced randomness extractors as a way to "purify" some shared -bits of entropy between Alice and Bob. Sending bits over a channel to which Eve has only limited access is simply a way of establishing these initial bits of entropy. The fact that Eve has some knowledge about the seed is unimportant since we use a strong seeded extractor.We can determine what the constants and have to be: From Eve's perspective the cq state of the key shared by Alice and Bob is Assuming , this state has min entropy so we must choose . Selecting among a 2-universal family of hash functions, we can choose as large as , as seen in the last session.
Remark. Of course the same protocol works for other restrictions on the channel, for example if Eve receives all sent bits correctly but only has limited memory.
Before we introduce a key distribution algorithm that works without additional restrictions on potential eavesdroppers, we need to address the assumption that Alice and Bob have access to a classical authenticated channel. There are generally two approaches to implementing an authenticated channel: Message Authentication Codes (MACs) and Digital Signatures. However, both approaches have drawbacks in a quantum key distribution context. MACs use private key cryptography --- so Alice and Bob already need to have a shared private key in advance! Digital Signatures, on the other hand, do not require an established private key, but make use of computational assumptions that generally no longer hold in the quantum era.Does this mean that the CAC assumption is too strong? The answer is nuanced. Let us take a look at both approaches individually.The idea behind message authentication codes is that based on a shared private key, Alice generates a tag for her message. With the same key, Bob can verify the validity of the tag for a given message. Formally, a message authentication code is a pair of functions
, which takes a message and a key, and returns a tag.
, which takes a message, a key, and a claimed tag for the message. It then returns whether the tag is valid for the message.
Both functions are required to run in polynomial time.A MAC is correct if
It is secure if, informally speaking, it is impossible for an adversary to generate a new pair of a message and a corresponding valid tag, even if he has access to arbitrarily many valid (message, tag) pairs (except with negligible probability).<br>
Example. An example of a one-time MAC<a data-footref="[inline0" href="#fn-1-21e7701b4dc4c86a" class="footnote-link" target="_self" rel="noopener nofollow">[1]</a> can be constructed using a 2-universal family of hash functions. Given such a family , The key is an element .
.
. Obviously this scheme is correct. Moreover it is secure by the 2-universality of : Suppose an adversary is given a single valid pair . Since is in particular -universal, the value of does not tell them anything about . Hence the only way to generate a new valid pair is to guess , which is successful with probability For maximal security, one would choose to be as large as possible, i.e. . Note, however, that any -universal family of hash functions needs to have at least elements, so the key needs to have length , that is, be just as long as the message.<br>Under the assumption that one-way functions exist<a data-footref="[inline1" href="#fn-2-21e7701b4dc4c86a" class="footnote-link" target="_self" rel="noopener nofollow">[2]</a>, one can find secure MACs that use shorter keys or allow reusing a key arbitrarily many times. In the context of key distribution algorithms, however, the conceptual problem that Alice and Bob need to already share a private key remains.As opposed to MACs, digital signatures make use of public-key cryptography. The idea is that Alice generates a pair of a public and a private key. Alice keeps her private key secret and shares her public key. A digital signature scheme is then a pair of functions , which takes a message and a private key, and outputs a signature. , which takes a message, a public key, and a claimed signature and outputs whether the signature is valid.
Both functions are required to run in polynomial time, may be probabilistic.The scheme is correct if
Security is defined similarly as for MACs.<br>
Example. A common digital signature scheme<a data-footref="[inline2" href="#fn-3-21e7701b4dc4c86a" class="footnote-link" target="_self" rel="noopener nofollow">[3]</a> is based on RSA. Here we choose two large primes and let . We then choose a positive integer and compute a such that . The public key is , the private key is .
We then let where is an embedding of the message space into .
Of course, the above algorithm is no longer secure in a post-quantum setting. An obvious idea is to base the signature scheme on a post-quantum cryptographic algorithm like LWE instead. However, these types of algorithms are exactly what quantum key distribution is supposed to replace! A slightly more convincing argument for digital signatures is that keys generated by a quantum key distribution protocol enjoy everlasting security, even if the authentication scheme underlying the CAC is broken afterwards. It suffices for the CAC to remain authenticated for the duration of the protocol, which is at most on the order of seconds. The signature scheme used to implement it may hence not necessarily need to be provably secure as long as it is "strong enough". As an example of an actual quantum key distribution protocol, we look at the well-known BB84 protocol, proposed by Bennett and Brassard in 1984.
Protocol 2 -- BB-84. Fix a large integer and let .
Alice chooses strings and uniformly at random. She sends Bob each bit by encoding as a quantum state according to as .
Bob chooses a string uniformly at random, and measures the th received qubit in the basis corresponding to . This yields a string .
Bob tells Alice over the CAC that he has received and measured all the qubits. Alice and Bob exchange their basis strings over the CAC.
Alice and Bob discard all bits of and respectively where , yielding strings and Alice and Bob check for eavesdroppers:
a. Alice picks a random subset and tells Bob over the CAC.
b. Alice and Bob exchange and over the CAC. They compute the number of errors .
c. If , Alice and Bob abort the protocol. Otherwise they proceed with the strings and .
Alice and Bob perform privacy amplification: Alice picks a random seed and computes . She then sends to Bob, who computes . Consider the following example run of the protocol.+------------------+------------------+------------------+------------------+------------------+------------------+------------------+------------------+------------------+
| | 0 | 1 | 1 | 0 | 1 | 0 | 0 | 1 |
+------------------+------------------+------------------+------------------+------------------+------------------+------------------+------------------+------------------+
| | | | | | | | | |
+------------------+------------------+------------------+------------------+------------------+------------------+------------------+------------------+------------------+
| Sent | | | | | | | | |
+------------------+------------------+------------------+------------------+------------------+------------------+------------------+------------------+------------------+
| | | | | | | | | |
+------------------+------------------+------------------+------------------+------------------+------------------+------------------+------------------+------------------+
| Measured | | | | | | | | |
+------------------+------------------+------------------+------------------+------------------+------------------+------------------+------------------+------------------+
| | 0 | | 1 | | | 0 | | 1 |
+------------------+------------------+------------------+------------------+------------------+------------------+------------------+------------------+------------------+It is not hard to see that the protocol is correct. Clearly, when and agree then so will and . It follows that and hence . The security of BB-84 is intuitively clear: If Eve tries to measure Alice's qubit in a basis that does not agree with the one that Alice used for the encoding, she will introduce an error in Bob's measurement with probability . The requirement that the error rate be on a random subset of qubits of size then lower-bounds the min-entropy . A round of privacy amplification then extracts a key that Eve is ignorant about.In this sense, the general idea mirrors our toy protocol.Formalising this idea is more involved, in particular because Eve might apply more involved attacks like entangling her system with the sent qubits. In fact it is so difficult that it took more than 20 years to give a proof that does not only work asymptotically. We will show security asymptotically in a restricted case. To simplify the analysis, we first adapt the protocol somewhat. We assume that Alice and Bob share an EPR pair, and Alice measures her part of the state in some choice of basis to obtain the random string . We also allow a non-zero error rate in step 7.
Protocol 3 -- Purified BB-84 Fix a large integer and let Alice prepares EPR pairs and sends the second qubit to Bob respectively.
Alice chooses a string uniformly at random. She then measures the first qubit of the th EPR pair in the or basis depending on to obtain a random string .
Bob chooses a string uniformly at random, and measures the second qubit of the th EPR pair in the basis corresponding to . This yields a string .
Bob tells Alice over the CAC that he has measured all the qubits. Alice and Bob exchange their basis strings over the CAC.
Alice and Bob discard all bits of and respectively where , yielding strings and Alice and Bob check for eavesdroppers:
a. Alice picks a random subset and tells Bob over the CAC.
b. Alice and Bob exchange and over the CAC. They compute the error rate , where .
c. If is too large, Alice and Bob abort the protocol. Alice and Bob perform privacy amplification on the remaining bits. Note that the use of entangled states is equivalent to the original approach. Moreover, the weakened requirements on the error rate make Protocol 3 generally less secure than Protocol 2. If we can prove security for this modified protocol, then the original protocol must also be secure.Next, we significantly increase the power of an eavesdropper. We assume that it is Eve who initially prepares a state , whose and systems consist of qubits respectively, that she distributes to Alice and Bob. Alice and Bob then proceed as usual with the measurements on their respective qubits.If we just recover Protocol 3. Any possible attack (excluding side-channel attacks) can be modeled as Eve simply distributing a specific . On the other hand, not every state can be achieved by only interacting with the qubits sent over the channel. Eve's power has strictly increased.We will show that despite this additional power given to Eve, the protocol is still secure, assuming is not entangled between rounds. When there are no restrictions on the protocol is still secure, but the analysis becomes too complicated to cover here.To show that Protocol 3 is secure, it suffices to show that it is able to detect whether is close enough to . The obvious way Alice and Bob could verify this is to add an initial step to the protocol as follows: After receiving from Eve, Alice and Bob jointly measure their qubit pairs using the POVM . If for some more than of the pairs are found not to be in state , Alice and Bob abort the protocol. Such a step would also make step 7 of Protocol 3 redundant. Of course this hypothetical step 0 is impossible to implement, because Alice and Bob can only perform local measurements on their respective systems. We argue that step 7 is essentially equivalent to step 0. Lemma 1. Let be a tripartite state, where and are systems of a single qubit. Then the probability that respective measurements of systems and in the computational basis result in matching outcomes is exactly , where
Similarly, the probability that the outcomes match when measuring in the Hadamard basis is , where *Proof.*
The probability of matching measurement outcomes in the computational basis is given by
$$ P_{\text{match}} = \braket{00 | \rho_{AB} | 00} + \braket{11 | \rho_{AB} | 11} = \operatorname{Tr} ((\ket{00}\bra{00} + \ket{11}\bra{11})\rho_{AB}) $$
and we have
$$ \ket{\Psi^+}\bra{\Psi^+} + \ket{\Psi^-}\bra{\Psi^-} $$
$$ = \frac{1}{2}(\ket{00}\bra{00} + \ket{00}\bra{11} + \ket{11}\bra{00} + \ket{11}\bra{11} + \ket{00}\bra{00} - \ket{00}\bra{11} - \ket{11}\bra{00} + \ket{11}\bra{11}) $$
$$ = \ket{00}\bra{00} + \ket{11}\bra{11}. $$
Completely analogous, in the Hadamard basis we have
$$ P_{\text{match}} = \operatorname{Tr}((\ket{++}\bra{++} + \ket{--}\bra{--})\rho_{AB}) $$
and $$ \ket{\Psi^+}\bra{\Psi^+} + \ket{\Phi^+}\bra{\Phi^+} = \ket{++}\bra{++} + \ket{--}\bra{--}. $$ Now consider an arbitrary that we assume to be of the form . Expressing the -marginal of a single round in the Bell basis yieldsThe probability that the POVM in step 0 measures is , while by Lemma 1 the probability of succeeding in step 7 of Protocol 3 is given byIn other words , so if the probability of success in step 7 is close to one, say , then the overlap with is correspondingly large, . Of course the converse holds trivially.However, this does not yet prove that step 0 and step 7 are essentially equivalent. This is because step 7 only tests a subset of the qubits. Intuitively however, since is chosen randomly, this testing step should upper bound the number of errors on the remaining qubits as well. We can make this precise through a Hoeffding-type inequality.
Lemma 2 (Tomamichel &amp; Leverrier). Let and consider binary random variables . Let be a uniformly random subset of of size . Then for any , it holds that We will let denote the indicator random variable such that if in step 7 of Protocol 3. We then let , and where is the largest tolerated error rate in step 7c. In the asymptotic limit, we may assume that the chosen in step 7a has size exactly , hence Lemma 2 applies. We thus get the boundwhich vanishes as .It follows that step 7 implies that the error rate on the whole qubit string is sufficiently low, which by our previous observations implies that the overlap of with is sufficiently high. This completes the asymptotic security proof of Protocol 3 in the restricted threat model. Since Protocol 3 is less secure than Protocol 2, we can conclude the security of BB-84.Until now, we assumed that all communication is error-free. Of course this is not the case, in particular not in the quantum case. Do our protocols break in the presence of errors?The answer is no, because we can perform error correction. In fact, since we distribute classical bitstrings, we may view the quantum protocol as a lossy classical channel and simply do classical error correction afterwards. There are many performant classical error correction codes.The general idea is that Alice sends a message to Bob through a lossy channel, who receives it as , where is a string of errors. They then exchange some additional information over the channel that allows Bob to make an estimate of based on .
Definition. An information reconciliation protocol for , lets Bob recover an estimate of given . It is -correct if .
It leaks bits if the total length of the messages exchanged over the channel is . In the context of key distribution it is important to limit the number of bits a protocol leaks. This is because any leaked bits reduce the min-entropy of the key. Concretely, we haveso if we leak bits, we can still be sure to have lost at most bits of min-entropy.An important class of information reconciliation protocols are built on linear codes.
Definition. An -ary linear code is a dimensional subspace of .
A linear code is also induced by a parity-check matrix by letting . The syndrome of a message is then given by . Protocol 4 -- Information Reconciliation through Linear Codes.
Let be a parity-check matrix. Assume Alice has sent a string that Bob received as . Alice sends over the public channel.
Bob computes and the syndrome of .
Based on the syndrome and the parity-check matrix , Bob determines an estimate of .
Bob computes . If induces an binary linear code, then Protocol 4 leaks bits, where can be chosen as low as . Of course, the larger our code and hence the smaller the syndrome, the harder the error-estimation becomes.The correctness completely depends on the chosen code.
Example.
Consider the binary linear code given by the parity-check matrix where Bob's error-estimation is based on the following table.
+----------+--------------+
| Syndrome |Error Estimate|
+----------+--------------+
|00 |000 |
+----------+--------------+
|01 |001 |
+----------+--------------+
|10 |100 |
+----------+--------------+
|11 |010 |
+----------+--------------+
Then Bob can correct any error of at most one bit-flip. Consequently, the code leaks bits and is -correct for
where is the probability of a single bit-flip occurring (assuming uncorrelated errors).
There is a theoretical minimum to the number of bits leaked for optimal information reconciliation. Suppose and are sampled bitwise from some joint probability distribution . Then the theoretical minimum number of bits that have to be leaked isThe efficiency of information reconciliation protocols is usually given in terms of a constant which says that the protocol leaks approximatelybits.Examples of codes that are widely in use are LDPC codes, for which is between and . <br>A one-time MAC is only secure if the key does not get reused between rounds. <a href="#fnref-1-21e7701b4dc4c86a" class="footnote-backref footnote-link" target="_self" rel="noopener nofollow">↩︎</a>
<br>Which is generally believed, even when taking quantum algorithms into account. <a href="#fnref-2-21e7701b4dc4c86a" class="footnote-backref footnote-link" target="_self" rel="noopener nofollow">↩︎</a>
<br>The actual signature scheme involves an additional hashing of the message. As described here, it is vulnerable to Existential Forgery. <a href="#fnref-3-21e7701b4dc4c86a" class="footnote-backref footnote-link" target="_self" rel="noopener nofollow">↩︎</a>
]]></description><link>quantum-crypto/session-3-qkd.html</link><guid isPermaLink="false">Quantum Crypto/Session 3 - QKD.md</guid><pubDate>Wed, 26 Nov 2025 12:32:36 GMT</pubDate></item><item><title><![CDATA[Session 2 - Improving Security]]></title><description><![CDATA[As previously, we have our protagonists Alice and Bob, trying to communicate in a secure manner, and an eavesdropper Eve, trying to intercept the communication.As we have seen in Session 1, Alice and Bob need a shared private key to be able to communicate.If Alice and Bob know each other well, they might attempt to build a private key from common shared knowledge, such as the flavor of the first cone of ice cream they shared, or the name of Bob's cats. Doing so will yield a somewhat "fairly" secret key.Info
This key will only be fairly secret, as other individuals might also know such shared information, and Eve might be able to gather some through various means.
Naturally, Alice and Bob want to find a scheme to create an actually secret key from this fairly secret starting key.Introducing privacy amplification :Alice and Bob share a "weak secret" which comes from some distribution , represented as a random variable called the source.
While the distribution of may not be known, is available to both parties.Eve possesses side information which might be correlated to , such as its first bit, its parity, or even some quantum state .The goal for Alice and Bob is to generate some such that from the point of view of Eve, (chosen from a distribution ) is (close to) uniformally random.Note
The size of will depend on how secret the original secret is. If there is not much that can be done.
Intuitively, this will be quantified by the min-entropy .
Let's first start with a simpler problem, Alice has some source from which she gathers a string , which is possibly correlated with , with the promise that (with this condition, is called a -source), and is tasked to generate such that the distribution is close to uniform even conditionned on . Similar setup as before, but Alice is on her own and does not have to coordinate with bob.Note
While Alice could just sample from an actually uniform distribution, or measure in the Hadamard basis a bunch of times, assume here that randomness is costly, and Alice does not have ready access to large amounts of randomness for free. The goal is to extract randomness from X.
If has a distribution consisting of i.i.d. variables , one can extract a single bit nearly uniformly by taking the parity of all the bitsExample i.i.d., take .
If has probability 3/4 of being 1, 1/4 of being 0, for we have , . Not quite uniform, but better than what we started with, and better still for increasing .
One can use the same approach for variables which aren't identically distributed, and get a single bit close to a uniform distribution. However this is not very efficient.Using a deterministic function to extract randomness (such as ) can only get you so far however, since for any , even if , there is no function that can always extract bits of randomness from .Instead, we need to expand the scope to seeded extractor functions, which use a seed as a source of randomness. However, since this randomness may be costly, the seed should be of relatively small size compared to and .Definition
A weak seeded extractor is a function Ext : such that for any -source ,
With uniformally distributed, independent from and .
One might think that one could simply use the seed as randomness, but Alice and Bob could not choose the same seed as a private key without communicating it publicly.This induces the definition for a strong seeded extractor, where the extractor's input is independent from the seedDefinition
A strong seeded extractor is a function Ext : such that for any -source ,
With uniformally distributed, independent from and .
Intuitively, the min-entropy gives an estimate of how much randomness there is to extract from , but it is a valid question to seek if a strong seeded extractor really can extract bits from if it has (meaning it is a -source).If , it is impossible to extract more than bits from while still being uncorrelated to , because you can guess the value of the extractor function by guessing first then applying the function, so , in particular .Conversely, we will show strong seeded extractors which achieve the extraction of a (mostly) uniform bits given being a -source.To build a strong seeded extractor, we will make use of hashing functions, which essentially take a long string and map them to shorter strings somewhat uniformally.We need to introduce classes of hashing functions families, namely 1-universal and 2-universal hash function families :1-universal family
A family of hashing functions , is 1-universal if for every and , Notice that the definition has and fixed, and the probability is over the family of functions.While a 1-universal family is enough to build a weak extractor, the following definition will let us build a strong one :2-universal family
A family of hashing functions , is 1-universal if for every and , Once given such a family, the extractor will use the seed to choose a function in the family, and apply it to to obtain . While the set of all functions is a 2-universal family, it has too many functions, and the seed would need to be too large to be practical.Instead, we will take functions in the field with elements, of the form where multiplication and addition are done in . This yields a family of functions which so happens to be a 2-universal family of hashing functions.Proof
Let , the probability of is the probability of , so and . This gives us a single possible choice for and , among , giving us the correct probability.
Notice how the functions map bit strings to bit strings, but we can simply toss the extra bits we don't want such that we are given bit strings, which still retains the 2-universality property.Our extractor will now be defined as To analyze the quality of the hashing functions, we will make use of the leftover hash lemma, which has different formulations depending on whether we consider quantum side information or not.In this case, we don't take into account from Eve, in which case the lemma is stated as follows:Lemma
Let integers, , , and a 2-universal family of hash functions. Then is a strong seeded extractor.
With our construction, the seed needs to be of length to be able to choose the hashing function, which is longer than the optimal seed length for the general case, but in the case of privacy amplification it is satisfactory. In the case without side information, we have .To prove this lemma, we will proceed in two steps. First we want to show that the error can be bounded by first showing a bound on the collision probability, and then we bound this collision probability and achieve the result of the bound on the error.As mentionned, we want to bound the error by something related to the collision probability where , and First part of the proof Using Cauchy-Schwartz inequality, After expanding the square and doing much simplification, Here we make use of the 2-universal family property to bound the collision probability .Second part of the proof
By expanding the square in the definition, we have
Using 2-universality,
Using the property of the minimal entropy being bounded by ,
Plugging this back into the first part we get that the error is bounded by proving the lemma.
To model side information, we will take to be a cq-state such that .Before proving the statement with side information, we need to dive into the measurements Eve can make. Indeed, finding the optimal measurement to guess can be solved via semi-definite programming, but there is no formula whenever . Instead, we will have to consider pretty good measurements.Choosing the measurement is positive semidefinite, but not necessarily normalized such that , except when the are perfectly distinguishable. We can instead define where and we use the Moore-Penrose pseudo-inverse, and is a POVM. One can show that the probability of guessing using and this POVM is the square of the optimal probability given any POVM.The proof with this pretty good measurement of the quality of our strong seeded extractor follows the same structure as the previous one, however it is quite more involved. If you do want to check it out, it starts page 13 of <a data-tooltip-position="top" aria-label="https://ocw.tudelft.nl/wp-content/uploads/LN_Week4.pdf" rel="noopener nofollow" class="external-link is-unresolved" href="https://ocw.tudelft.nl/wp-content/uploads/LN_Week4.pdf" target="_self">Lecture 4</a>.Using the results we have just shown, we can now devise a relatively simple protocol for privacy amplification:Privacy Amplification Protocol Alice and Bob build their shared weak secret , which might be correlated to Eve's .
Alice chooses a random seed for the extractor, and sends it to Bob through the public channel.
Alice and Bob each compute using the extractor built with hashing functions over the finite field with elements. This protocol is always correct since Alice and Bob perform the same computation (assuming they have the correct shared to start with).It is also secure, as our seeded extractor gives us the guarantee that is close to uniform, even conditionned on and . By using the 2-universal family of hash functions to build the strong seeded extractor, the protocol is now complete.This will be useful for next session, which will discuss key distribution protocols.]]></description><link>quantum-crypto/session-2-improving-security.html</link><guid isPermaLink="false">Quantum Crypto/Session 2 - Improving Security.md</guid><pubDate>Wed, 12 Nov 2025 12:44:59 GMT</pubDate></item><item><title><![CDATA[Quantum Cryptography Workgroup]]></title><description><![CDATA[
Biweekly work-group to learn quantum cryptography. We will follow the <a data-tooltip-position="top" aria-label="https://ocw.tudelft.nl/courses/quantum-cryptography/" rel="noopener nofollow" class="external-link is-unresolved" href="https://ocw.tudelft.nl/courses/quantum-cryptography/" target="_self">Lecture Notes</a> and <a data-tooltip-position="top" aria-label="https://www.cambridge.org/highereducation/books/introduction-to-quantum-cryptography/1D3D1FAE02AB40BE3780EBF9E461896B#overview" rel="noopener nofollow" class="external-link is-unresolved" href="https://www.cambridge.org/highereducation/books/introduction-to-quantum-cryptography/1D3D1FAE02AB40BE3780EBF9E461896B#overview" target="_self">Book</a> by Thomas Vidick and Stephanie Werner. We assume a basic knowledge of quantum information theory -- Density Matrices, POVMs. No cryptographic knowledge needed, even classical. We start from scratch. Need some enthusiastic volunteers to give talks :)
]]></description><link>quantum-crypto/quantum-cryptography-workgroup.html</link><guid isPermaLink="false">Quantum Crypto/Quantum Cryptography Workgroup.md</guid><pubDate>Wed, 05 Nov 2025 12:30:46 GMT</pubDate></item><item><title><![CDATA[Session 1 - Basics]]></title><description><![CDATA[We have our protagonists, Alice and Bob that want to communicate securely using some channel.We have an eavesdropper, Eve, who might have access to the communication channel that Alice and Bob use. To transmit their messages securely, Alice and Bob use a secret key, that is known only to the two of them, and not to Eve.These are called private-key cryptosystems. We do not yet care how this key is established in the first place, as it would have required some secure communication. We focus on this later sessionsSuch an encryption scheme consists of two processes, The encoding of the message given the key by applying the encoding function, This is done by Alice. Note that is called the plain-text and is called the cipher-text.
The decoding of the encrypted message given the key by applying the decoding function, This is done by Bob.
Obviously, we want such a scheme to give us the correct message after decoding. Therefore, we demand,Such a scheme of encoding is called correct! It is easy to come up with an example of such a scheme, for example let , that is send the message as it is.But as you realise, sending the message as it is is as insecure as it gets. So, we need a notion of security. Security of a private-key scheme
A encryption/decryption scheme is called secure if for all prior distributions over the messages, where For example, if Alice would be equally likely to send any out of messages to Bob, even after reading the encrypted message, Eve cannot guess the message better than with a probability of . It is easy to come up with an example of such a secure scheme as well, we can just ignore the message and send randomly any cipher-text , for example by flipping a coin and sending or . Goal
To design a scheme that is both correct and secure
Both the trivial schemes we designed didn't even use a key. How necessary is a key? Shannon Secrecy Condition
An encryption scheme can be both secure and correct if the number of possible keys is at least as large as number of possible messages. Proof Let . Let be the cipher-text that corresponds to some message and , i.e . This is intercepted by Eve.
Eve computes
This is the set of messages such that there is a key that maps them to the cipher-text . Clearly, .
Also . So there exists a message such that , i.e
We can assume that all messages have . Hence breaks the secrecy
To illustrate the proof, let us look at an encoding/decoding scheme. Let Alice send two bit messages, , , , by using a key of size , by flipping the first bit if and leaving it as it is otherwise. Let's say Alice send the message and with , without having any access to the cipher-text Eve's guess is correct only with probability. But after obtaining the cipher-text , Eve can compute the space of possibility for the message, i.e and , which implies that Eve can guess the plain-text with the probability . This implies that the scheme is not secure. So can we come up with a scheme that is both secure and correct with ? Info
Alice and Bob following encoding/decoding scheme, It is easy to check that this scheme is correct, i.e for any , we have We prove that is is also secure. Note that the security of a scheme highly depends on the knowledge of the eavesdropper about the secret key, encoded in the distribution . Here, a critical assumption that we make is that in Eve's perspective, all keys are equally likely, i.e . And let's assume there is some prior distribution over the messages, . Note that this may or may not be uniform. The goal is to show that for all , Proof Therefore this scheme has no extra "information" in the cipher-text given no-knowledge of the key. How can this be extended to a quantum bit? How to hide the quantum information from an eavesdropper? Let's say Alice sends a quantum state to Bob, and this is intercepted by Eve. How can we encode the state to ensure that Eve doesn't gain any access to the information? General Scheme
Encoding by Alice Decoding by Bob Again, we need to provide the definition of correctness and security of this scheme. The scheme is correct if The scheme is secure if Let us design a one time pad for qubits, with a key size of by adopting the bit flip approach. Then, for , we have, This is a correct scheme! But is it secure? Although for this works, it fails for , as you get We use bits to encode one qubit, Clearly the scheme is correct. But is it secure? Yes, by the following lemma Lemma This can be generalised to encoding qubits, by using bits. Can you write the encoding operation? In this section, we want to understand the privacy of the secret key that we use for the other cryptographic protocols. Let's say Alice owns a classical register with the key of size written. Eve can hold the following joint quantum state with the register. These are known as classical-quantum states. Ideally, we want this state to be of the form such that Eve can gain no information about the key that Alice and Bob possess. This condition means that Eve is ignorant of the key. To start with assume that the state of Alice and Eve is uncorrelated, but Alice (from the perspective of Eve!) has a state where is not a uniform distribution. One might be tempted to measure the uncertainty of the obtained key in terms of the Shannon Entropy of , as obviously this is maximised if and only if Alice's state is uniform. Let's assume that that the key is guaranteed to have an entropy of , and we wish to perform the one-time pad with this key. Is this good?Info
We can check that the following distribution, has the But this means that if Eve guesses the key to , she is right about percent of the time, and also decrypt the message with probability . So overall, even though the Shannon Entropy might be very high, the protocol is not cryptographically that secure. We need a better measure for uncertainty.Min-Entropy Calculating the minimum entropy for the previous distribution, we get for all sizes of the key, Effectively, the min entropy measures what Eve can do with the best guess of the key which is exactly as compared to Shannon entropy that measures what Eve can do with the average guess We have the following inequalities,
Given a classical quantum state, we want to define a quantity that captures the information Eve can gain about the classical register from her part of the correlated quantum state . Conditional Mutual Information (for CQ states) For a classical quantum state , Eve has all the information about the key. Therefore, we get choosing . For the uncorrelated state , we obtain
Moreover, we obtain this equal to for the following choice of POVMsuch that Therefore, we get .The final goal for today is to understand general "quantum" conditional min entropy. How can a quantum system gain maximum side information about another system? If it is completely correlated with the other system. In quantum mechanics, a stronger form of correlation also exists in form of the maximally entangled state. It is a quantum state that is "correlated" in all basis. We use this to define the conditional min-entropy for general quantum states. Intuitively, to be the adversary, we want to do the best quantum operation on Eve's end to gain maximum correlation with the "key" system, possibly in all basis!Conditional min-entropy (for general quantum states)
where and This is equivalent to the following definition, The proof of this equivalence will be shown in the next session. Right now, we look at the following exercise. Compute the Exercise Compute the for the state ]]></description><link>quantum-crypto/session-1-basics.html</link><guid isPermaLink="false">Quantum Crypto/Session 1 - Basics.md</guid><pubDate>Tue, 04 Nov 2025 23:40:44 GMT</pubDate></item></channel></rss>